{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25f0aa8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Sanket\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Importing libraries:\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ddcebc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>when a father is dysfunctional and is so selfi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>thanks for lyft credit i can't use cause they ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide society now motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>[2 2] huge fan fare and big talking before the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29525</th>\n",
       "      <td>31958</td>\n",
       "      <td>0</td>\n",
       "      <td>ate isz that youuu?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29526</th>\n",
       "      <td>31959</td>\n",
       "      <td>0</td>\n",
       "      <td>to see nina turner on the airwaves trying to w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29527</th>\n",
       "      <td>31960</td>\n",
       "      <td>0</td>\n",
       "      <td>listening to sad songs on a monday morning otw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29528</th>\n",
       "      <td>31961</td>\n",
       "      <td>1</td>\n",
       "      <td>sikh temple vandalised in in calgary wso conde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29529</th>\n",
       "      <td>31962</td>\n",
       "      <td>0</td>\n",
       "      <td>thank you for you follow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29530 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label                                              tweet\n",
       "0          1      0  when a father is dysfunctional and is so selfi...\n",
       "1          2      0  thanks for lyft credit i can't use cause they ...\n",
       "2          3      0                                bihday your majesty\n",
       "3          5      0                  factsguide society now motivation\n",
       "4          6      0  [2 2] huge fan fare and big talking before the...\n",
       "...      ...    ...                                                ...\n",
       "29525  31958      0                                ate isz that youuu?\n",
       "29526  31959      0  to see nina turner on the airwaves trying to w...\n",
       "29527  31960      0  listening to sad songs on a monday morning otw...\n",
       "29528  31961      1  sikh temple vandalised in in calgary wso conde...\n",
       "29529  31962      0                           thank you for you follow\n",
       "\n",
       "[29530 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train_cleaned.csv')\n",
    "#df.drop(['id'],axis=1, inplace=True)\n",
    "#pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None) # tto display full length text of column.\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56b5423",
   "metadata": {},
   "source": [
    "# Labels are as follows:\n",
    "label '1' ---> racist/sexist tweet           \n",
    "label '0' ---> not racist/sexist tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc7d62f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape:  (29530, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    27517\n",
       "1     2013\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Dataset shape: \", df.shape)\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cd854e",
   "metadata": {},
   "source": [
    "# Cleaning data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d82b50",
   "metadata": {},
   "source": [
    "### Cleaning and removing Punctuations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7585b7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "521d5d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet'] = df['tweet'].astype(str)\n",
    "punctuations_list = string.punctuation\n",
    "def cleaning_punctuations(text):\n",
    "    translator = str.maketrans('', '', punctuations_list)\n",
    "    return text.translate(translator)\n",
    "\n",
    "df['tweet'] = df['tweet'].apply(lambda x: cleaning_punctuations(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f929337",
   "metadata": {},
   "source": [
    "### Removing Stopwords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca41a3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = stopwords.words('english')\n",
    "df['tweet'] = df['tweet'].apply(lambda x: ' '.join([word for word in x.split() if word not in (sw)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452b4a14",
   "metadata": {},
   "source": [
    "### Removing Numeric numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1980b639",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_numbers(text):\n",
    "    return re.sub('[0-9]+', '', text)\n",
    "\n",
    "df['tweet'] = df['tweet'].apply(lambda text: cleaning_numbers(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428fc42f",
   "metadata": {},
   "source": [
    "### Tokenizing Tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9cce2c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[father, dysfunctional, selfish, drags, kids, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[thanks, lyft, credit, cant, use, cause, dont,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>[bihday, majesty]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>[factsguide, society, motivation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>[huge, fan, fare, big, talking, leav, chaos, p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0  [father, dysfunctional, selfish, drags, kids, ...\n",
       "1   2      0  [thanks, lyft, credit, cant, use, cause, dont,...\n",
       "2   3      0                                  [bihday, majesty]\n",
       "3   5      0                  [factsguide, society, motivation]\n",
       "4   6      0  [huge, fan, fare, big, talking, leav, chaos, p..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = (word_tokenize(i) for i in df.tweet)\n",
    "df['tweet'] = df['tweet'].apply(nltk.word_tokenize)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecef1929",
   "metadata": {},
   "source": [
    "### Stemming:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b6de99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemm = SnowballStemmer('english')\n",
    "df['tweet'] = df['tweet'].apply(lambda x: [stemm.stem(y) for y in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfe3090",
   "metadata": {},
   "source": [
    "### Splitting data into Train and Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1b971a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['tweet'].astype(str)  # Converting to string, because vectorizer does'nt accept list.\n",
    "y = df['label'].astype(str)  # Converting to string, because vectorizer does'nt accept list.\n",
    "X_train, X_test, y_train, y_test =  train_test_split(X, y, test_size = 0.2, random_state = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53dbeb52",
   "metadata": {},
   "source": [
    "# Transforming Dataset using TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a31e440",
   "metadata": {},
   "source": [
    "### Fitting the Count Vectorizer"
   ]
  },
  {
   "cell_type": "raw",
   "id": "43871a7a",
   "metadata": {},
   "source": [
    "# Extracting features using CountVectorizer - unigrams\n",
    "vectoriser = CountVectorizer(ngram_range=(1,2))\n",
    "vectoriser.fit(X_train)\n",
    "print('No. of feature_words: ', len(vectoriser.get_feature_names()))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fa39ec",
   "metadata": {},
   "source": [
    "### Fitting the TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ebd4d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of feature_words:  154710\n"
     ]
    }
   ],
   "source": [
    "# Extracting features using TF-IDF (1,2) - unigrams and bigrams\n",
    "vectoriser = TfidfVectorizer(ngram_range=(1,2), max_features=500000)\n",
    "vectoriser.fit(X_train)\n",
    "print('No. of feature_words: ', len(vectoriser.get_feature_names()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3578df7",
   "metadata": {},
   "source": [
    "### Transforming the data using TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ddb2880b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = vectoriser.transform(X_train)\n",
    "X_test  = vectoriser.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef805697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a dictionary with four models with some parameters:\n",
    "model_params = {\n",
    "    \n",
    "    'SVC' :{\n",
    "        'model' : SVC(),\n",
    "        'params' : {\n",
    "            'C': [0.1, 1, 10, 100, 1000], 'gamma': [1, 0.1, 0.01, 0.001], 'kernel': ['rbf','linear','poly','sigmoid']\n",
    "        }\n",
    "    },\n",
    "\n",
    "    'MultinomialNB' :{\n",
    "        'model' : MultinomialNB(),\n",
    "        'params' : {\n",
    "            'alpha' : np.linspace(0.5, 1.5, 6), 'fit_prior' : [True, False]\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    'logistics_regression' :{\n",
    "        'model' : LogisticRegression(solver = 'lbfgs', multi_class = 'auto'),\n",
    "        'params' : {\n",
    "            'C' : [0.1, 1, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100], 'solver' : ['lbfgs', 'liblinear']\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    'random_forest' :{\n",
    "        'model' : RandomForestClassifier(),\n",
    "        'params' : {\n",
    "            'n_estimators' : [1,5,10,15,20,25,30,35,40,45,50,55,60,65,70,75,80,85,90,95,100,200,300,400], \n",
    "            'max_depth':[20,30,None], 'criterion':['gini','entropy']\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02b04f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC()\n",
      "\n",
      "Fitting...\n",
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n",
      "[[5377  113]\n",
      " [ 142  274]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98      5490\n",
      "           1       0.71      0.66      0.68       416\n",
      "\n",
      "    accuracy                           0.96      5906\n",
      "   macro avg       0.84      0.82      0.83      5906\n",
      "weighted avg       0.96      0.96      0.96      5906\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "MultinomialNB()\n",
      "\n",
      "Fitting...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[[5490    0]\n",
      " [ 367   49]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      5490\n",
      "           1       1.00      0.12      0.21       416\n",
      "\n",
      "    accuracy                           0.94      5906\n",
      "   macro avg       0.97      0.56      0.59      5906\n",
      "weighted avg       0.94      0.94      0.91      5906\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "LogisticRegression()\n",
      "\n",
      "Fitting...\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "[[5428   62]\n",
      " [ 174  242]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      5490\n",
      "           1       0.80      0.58      0.67       416\n",
      "\n",
      "    accuracy                           0.96      5906\n",
      "   macro avg       0.88      0.79      0.83      5906\n",
      "weighted avg       0.96      0.96      0.96      5906\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "RandomForestClassifier()\n",
      "\n",
      "Fitting...\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "[[5471   19]\n",
      " [ 246  170]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      5490\n",
      "           1       0.90      0.41      0.56       416\n",
      "\n",
      "    accuracy                           0.96      5906\n",
      "   macro avg       0.93      0.70      0.77      5906\n",
      "weighted avg       0.95      0.96      0.95      5906\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_score</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.956824</td>\n",
       "      <td>{'C': 10, 'gamma': 1, 'kernel': 'sigmoid'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.937860</td>\n",
       "      <td>{'alpha': 0.5, 'fit_prior': True}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logistics_regression</td>\n",
       "      <td>0.960041</td>\n",
       "      <td>{'C': 100, 'solver': 'liblinear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.955130</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': None, 'n_es...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  best_score  \\\n",
       "0                   SVC    0.956824   \n",
       "1         MultinomialNB    0.937860   \n",
       "2  logistics_regression    0.960041   \n",
       "3         random_forest    0.955130   \n",
       "\n",
       "                                         best_params  \n",
       "0         {'C': 10, 'gamma': 1, 'kernel': 'sigmoid'}  \n",
       "1                  {'alpha': 0.5, 'fit_prior': True}  \n",
       "2                  {'C': 100, 'solver': 'liblinear'}  \n",
       "3  {'criterion': 'gini', 'max_depth': None, 'n_es...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# implemented GridSearchCV for four models using a loop and a previously created dictionary\n",
    "# in the created variable 'scores', results are stored for each model such as: model, best_score and best_params.\n",
    "\n",
    "scores = []\n",
    "\n",
    "for model_name, mp in model_params.items():\n",
    "    clf = GridSearchCV(mp['model'], mp['params'], cv=5, n_jobs=-1, verbose=1) # Using Cross Validation of 5 and n_jobs=-1 for fast training by using all the processors\n",
    "    print(mp['model'])\n",
    "    print('\\nFitting...')\n",
    "    best_model = clf.fit(X_train, y_train)                      # Training the model\n",
    "    clf_pred = best_model.predict(X_test)                       # Predicting the results\n",
    "    print(confusion_matrix(y_test,clf_pred))                    # Printing Confusion Matrix\n",
    "    print(metrics.classification_report(y_test, clf_pred))      # Printing Classification Report\n",
    "    scores.append({                                             # Appending results to 'scores' list\n",
    "        'model' : model_name,\n",
    "        'best_score' : best_model.score(X_test, y_test),\n",
    "        'best_params' : clf.best_params_\n",
    "    })\n",
    "    print('\\nScore is appended.\\n')\n",
    "    \n",
    "# Creating data frame with model, best scores and best params:\n",
    "res = pd.DataFrame(scores, columns=['model', 'best_score', 'best_params'])\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665632db",
   "metadata": {},
   "source": [
    "# Conclusion:\n",
    "From above result, it can be concluded that **SVC has better precision, recall and F1-score for 'Toxic' label**. So, I'm going to train **SVC model** with 100% train data, so that it get more better training and will use test set to predict & label them and will use that file for submission. Creating a new notebook for this.\n",
    "\n",
    "Note: I have also used **'Count Vectorizer -> ngram_range=(1,1): unigrams and ngram_range=(1,2): unigram - bigrams'**, that gave very close result to **'TF-IDF Vectorizer -> ngram_range=(1,1): unigrams and ngram_range=(1,2): unigram - bigrams'**, however, **'TF-IDF with ngram_range=(1,2): unigram - bigrams'** turns out to be little bit better than **'Count Vectorizer -> ngram_range=(1,1): unigrams and ngram_range=(1,2): unigram - bigrams'** and **'TF-IDF ngram_range=(1,1): unigram'**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a82691",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
